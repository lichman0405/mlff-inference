# EquiformerV2 Inference å®‰è£…æŒ‡å—

> **EquiformerV2**: åŸºäºç­‰å˜ Transformer çš„é«˜ç²¾åº¦åŠ›åœºæ¨¡å‹  
> **å¼€å‘å›¢é˜Ÿ**: Meta AI / UC Berkeley - Open Catalyst Project  
> **ç‰¹è‰²**: S2EF ç²¾åº¦ä¼˜å¼‚ã€E(3) ç­‰å˜æ¶æ„ã€å¤§è§„æ¨¡ææ–™é¢„è®­ç»ƒ

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿè¦æ±‚](#1-ç³»ç»Ÿè¦æ±‚)
2. [å®‰è£…æ–¹æ³•](#2-å®‰è£…æ–¹æ³•)
3. [éªŒè¯å®‰è£…](#3-éªŒè¯å®‰è£…)
4. [GPU é…ç½®](#4-gpu-é…ç½®)
5. [å¸¸è§é—®é¢˜](#5-å¸¸è§é—®é¢˜)
6. [ä¾èµ–è¯´æ˜](#6-ä¾èµ–è¯´æ˜)

---

## 1. ç³»ç»Ÿè¦æ±‚

### æœ€ä½é…ç½®
- **æ“ä½œç³»ç»Ÿ**: Linux, macOS, Windows (WSL2)
- **Python**: 3.9 - 3.11 (æ¨è 3.10)
- **å†…å­˜**: 12GB RAM (æ¨è 16GB+)
- **ç£ç›˜**: 8GB å¯ç”¨ç©ºé—´

### GPU ç‰ˆæœ¬é¢å¤–è¦æ±‚
- **GPU**: NVIDIA GPU (è®¡ç®—èƒ½åŠ› >= 6.0)
- **CUDA**: 11.8 æˆ– 12.1+
- **GPU æ˜¾å­˜**: >= 12GB (æ¨è >= 16GB)
- **é©±åŠ¨**: NVIDIA Driver >= 450.80.02

---

## 2. å®‰è£…æ–¹æ³•

### æ–¹æ³• 1: Pip å®‰è£… (æ¨è)

#### CPU ç‰ˆæœ¬
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n equiformerv2-cpu python=3.10
conda activate equiformerv2-cpu

# å®‰è£… PyTorch (CPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# å®‰è£… EquiformerV2 æ ¸å¿ƒä¾èµ–
pip install equiformer-v2 e3nn

# å®‰è£…åŸå­æ¨¡æ‹Ÿç¯å¢ƒ
pip install ase phonopy pymatgen

# å®‰è£…æœ¬æ¨ç†åŒ…
cd EquiformerV2_inference
pip install -r requirements-cpu.txt
```

#### GPU ç‰ˆæœ¬
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n equiformerv2-gpu python=3.10
conda activate equiformerv2-gpu

# å®‰è£… PyTorch (GPU) - æ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©
# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£… torch-geometric åŠå…¶ä¾èµ–
pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html
pip install torch-geometric

# å®‰è£… EquiformerV2 æ ¸å¿ƒä¾èµ–
pip install equiformer-v2 e3nn

# å®‰è£…åŸå­æ¨¡æ‹Ÿç¯å¢ƒ
pip install ase phonopy pymatgen spglib

# å®‰è£…æœ¬æ¨ç†åŒ…
cd EquiformerV2_inference
pip install -r requirements-gpu.txt
```

### æ–¹æ³• 2: Conda å®Œæ•´ç¯å¢ƒ

```bash
# åˆ›å»ºç¯å¢ƒå¹¶å®‰è£…æ‰€æœ‰ä¾èµ–
conda create -n equiformerv2 python=3.10
conda activate equiformerv2

# å®‰è£… PyTorch (GPU)
conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia

# æˆ–å®‰è£… PyTorch (CPU)
conda install pytorch cpuonly -c pytorch

# å®‰è£… PyTorch Geometric
conda install pyg -c pyg

# å®‰è£… E3NN
pip install e3nn

# å®‰è£…å…¶ä»–ä¾èµ–
pip install equiformer-v2 ase phonopy pymatgen scipy h5py matplotlib pandas tqdm pyyaml spglib
```

### æ–¹æ³• 3: å¼€å‘è€…å®‰è£… (ä»æºç )

```bash
# å…‹éš†ä»“åº“
cd EquiformerV2_inference/equiformerv2-inference

# å®‰è£…å¼€å‘æ¨¡å¼
pip install -e ".[dev]"

# å®‰è£…æµ‹è¯•ä¾èµ–
pip install pytest pytest-cov
```

---

## 3. éªŒè¯å®‰è£…

### 3.1 æ£€æŸ¥ Python åŒ…

```bash
# æ£€æŸ¥ EquiformerV2 ç‰ˆæœ¬
python -c "import equiformer_v2; print(equiformer_v2.__version__)"

# æ£€æŸ¥ E3NN
python -c "import e3nn; print(f'E3NN version: {e3nn.__version__}')"

# æ£€æŸ¥ torch-geometric (GPU ç‰ˆæœ¬)
python -c "import torch_geometric; print(f'PyG version: {torch_geometric.__version__}')"

# æ£€æŸ¥æ¨ç†åŒ…
python -c "from equiformerv2_inference import EquiformerV2Inference; print('EquiformerV2 Inference OK')"

# æ£€æŸ¥å‘½ä»¤è¡Œå·¥å…·
equiformerv2-infer --help
```

### 3.2 è¿è¡Œæµ‹è¯•

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
cd EquiformerV2_inference/equiformerv2-inference
python -m pytest tests/test_install.py -v

# å®Œæ•´æµ‹è¯•å¥—ä»¶
python -m pytest tests/ -v

# è¿è¡Œç¤ºä¾‹è„šæœ¬
python examples/01_single_point.py
```

### 3.3 GPU åŠŸèƒ½æµ‹è¯•

```python
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"cuDNN version: {torch.backends.cudnn.version()}")
print(f"GPU count: {torch.cuda.device_count()}")

if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
```

### 3.4 E3NN åŠŸèƒ½æµ‹è¯•

```python
import torch
from e3nn import o3

# æµ‹è¯•çƒè°å‡½æ•°
irreps = o3.Irreps("1e + 2e")
print(f"Irreps: {irreps}")

# æµ‹è¯•æ—‹è½¬ç­‰å˜æ€§
x = torch.randn(10, irreps.dim)
print(f"E3NN test passed! Tensor shape: {x.shape}")
```

---

## 4. GPU é…ç½®

### 4.1 é€‰æ‹© GPU è®¾å¤‡

```python
from equiformerv2_inference import EquiformerV2Inference

# è‡ªåŠ¨æ£€æµ‹ (ä¼˜å…ˆ GPU)
calc = EquiformerV2Inference(device="auto")

# å¼ºåˆ¶ä½¿ç”¨ GPU 0
calc = EquiformerV2Inference(device="cuda:0")

# å¼ºåˆ¶ä½¿ç”¨ CPU
calc = EquiformerV2Inference(device="cpu")
```

### 4.2 å¤š GPU ç¯å¢ƒ

```python
import torch

# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨ GPU
for i in range(torch.cuda.device_count()):
    props = torch.cuda.get_device_properties(i)
    print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    print(f"  Compute capability: {props.major}.{props.minor}")
    print(f"  Total memory: {props.total_memory / 1024**3:.1f} GB")

# ä½¿ç”¨ç‰¹å®š GPU
calc = EquiformerV2Inference(device="cuda:1")

# ç¯å¢ƒå˜é‡æ§åˆ¶å¯è§ GPU
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0,2"  # åªä½¿ç”¨ GPU 0 å’Œ 2
```

### 4.3 å†…å­˜ä¼˜åŒ–

```python
# ä½¿ç”¨æ··åˆç²¾åº¦ (èŠ‚çœæ˜¾å­˜ï¼Œç•¥å¾®é™ä½ç²¾åº¦)
calc = EquiformerV2Inference(
    device="cuda",
    precision="float16"  # æˆ– "bfloat16" (A100)
)

# æ‰¹å¤„ç†å¤§å°è°ƒæ•´
calc = EquiformerV2Inference(
    device="cuda",
    batch_size=16  # æ ¹æ®æ˜¾å­˜è°ƒæ•´ (é»˜è®¤ 32)
)

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (è®­ç»ƒç”¨ï¼Œæ¨ç†é€šå¸¸ä¸éœ€è¦)
calc = EquiformerV2Inference(
    device="cuda",
    gradient_checkpointing=True
)
```

### 4.4 æ€§èƒ½ä¼˜åŒ–

```python
import torch

# å¯ç”¨ TF32 (Ampere æ¶æ„: A100, RTX 30 ç³»åˆ—)
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

# å¯ç”¨ cuDNN benchmark (å›ºå®šè¾“å…¥å¤§å°æ—¶)
torch.backends.cudnn.benchmark = True

# è®¾ç½® cuDNN deterministic (ç‰ºç‰²æ€§èƒ½ä¿è¯å¯é‡å¤æ€§)
torch.backends.cudnn.deterministic = False  # æ¨ç†æ—¶è®¾ä¸º False
```

| CUDA ç‰ˆæœ¬ | PyTorch ç‰ˆæœ¬ | æ¨èä½¿ç”¨ |
|-----------|-------------|---------|
| 11.8 | 2.0.0+ | âœ… ç¨³å®š |
| 12.1 | 2.1.0+ | âœ… æ¨è |
| 12.4 | 2.3.0+ | âš ï¸ æµ‹è¯•ä¸­ |

æ£€æŸ¥å…¼å®¹æ€§ï¼š
```bash
# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# æ£€æŸ¥ PyTorch CUDA ç‰ˆæœ¬
python -c "import torch; print(torch.version.cuda)"
```

---

## 5. å¸¸è§é—®é¢˜

### 5.1 å®‰è£…é—®é¢˜

#### Q1: PyG æ‰©å±•å®‰è£…å¤±è´¥

**é—®é¢˜**: `torch-scatter`, `torch-sparse` ç­‰å®‰è£…å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ³• 1: ä½¿ç”¨é¢„ç¼–è¯‘è½®å­
pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html

# æ–¹æ³• 2: ä½¿ç”¨ conda
conda install pyg -c pyg

# æ–¹æ³• 3: ä»æºç ç¼–è¯‘
export TORCH_CUDA_ARCH_LIST="7.0;7.5;8.0;8.6"
pip install torch-scatter torch-sparse --no-cache-dir
```

#### Q2: ImportError: cannot import name 'EquiformerV2Inference'

**é—®é¢˜**: æ¨ç†åŒ…æœªæ­£ç¡®å®‰è£…

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é‡æ–°å®‰è£…æ¨ç†åŒ…
cd equiformerv2-inference
pip install -e . --force-reinstall

# æ£€æŸ¥ Python è·¯å¾„
python -c "import sys; print(sys.path)"
```

#### Q3: E3NN å®‰è£…å¤±è´¥

**é—®é¢˜**: `pip install e3nn` å¤±è´¥æˆ–ç‰ˆæœ¬ä¸å…¼å®¹

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å®‰è£…ç‰¹å®šç‰ˆæœ¬
pip install "e3nn>=0.5.0,<0.6.0"

# æˆ–ä» conda-forge å®‰è£…
conda install -c conda-forge e3nn

# æˆ–ä»æºç å®‰è£…
pip install git+https://github.com/e3nn/e3nn.git
```

#### Q4: NumPy ç‰ˆæœ¬å†²çª

**é—®é¢˜**: `numpy>=2.0` ä¸æŸäº›åŒ…ä¸å…¼å®¹

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é™çº§åˆ° NumPy 1.x
pip install "numpy>=1.21.0,<2.0.0"

# æˆ–ä½¿ç”¨å…¼å®¹çš„ NumPy 2.0
pip install --upgrade numpy scipy
```

#### Q5: ASE ç‰ˆæœ¬ä¸å…¼å®¹

**é—®é¢˜**: ASE æ¥å£å˜åŒ–å¯¼è‡´é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å®‰è£…æ¨èç‰ˆæœ¬
pip install "ase>=3.22.0,<3.24.0"

# æˆ–æ›´æ–°åˆ°æœ€æ–°
pip install --upgrade ase
```

### 5.2 è¿è¡Œæ—¶é—®é¢˜

#### Q6: æ¨¡å‹åŠ è½½é”™è¯¯

**é—®é¢˜**: `FileNotFoundError: Model checkpoint not found`

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ³• 1: æ˜¾å¼æŒ‡å®šæ¨¡å‹è·¯å¾„
calc = EquiformerV2Inference(
    model_path="/path/to/equiformer_v2_checkpoint.pt"
)

# æ–¹æ³• 2: ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
from equiformerv2_inference.utils import download_pretrained_model
model_path = download_pretrained_model("EquiformerV2-31M-S2EF")
calc = EquiformerV2Inference(model_path=model_path)

# æ–¹æ³• 3: ä» OCP æ¨¡å‹åº“ä¸‹è½½
# è®¿é—®: https://github.com/Open-Catalyst-Project/ocp
```

#### Q7: CUDA out of memory

**é—®é¢˜**: GPU æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å‡å°æ‰¹å¤„ç†å¤§å°
calc = EquiformerV2Inference(batch_size=8)

# 2. ä½¿ç”¨æ··åˆç²¾åº¦
calc = EquiformerV2Inference(precision="float16")

# 3. æ¸…ç† GPU ç¼“å­˜
import torch
torch.cuda.empty_cache()

# 4. é™åˆ¶ PyTorch å†…å­˜åˆ†é…
import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:512"

# 5. åˆ‡æ¢åˆ° CPU
calc = EquiformerV2Inference(device="cpu")
```

#### Q8: å¯¼å…¥é”™è¯¯

**é—®é¢˜**: `ModuleNotFoundError: No module named 'equiformer_v2'` æˆ– `e3nn`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é‡æ–°å®‰è£…ä¾èµ–
pip install --upgrade equiformer-v2 e3nn torch-geometric

# æ£€æŸ¥ç¯å¢ƒ
conda list | grep -E "equiformer|e3nn|torch"

# æ£€æŸ¥ Python è·¯å¾„
python -c "import sys; print('\n'.join(sys.path))"

# é‡æ–°å®‰è£…æ¨ç†åŒ…
cd EquiformerV2_inference/equiformerv2-inference
pip install -e .
```

#### Q9: Phonopy è®¡ç®—å¤±è´¥

**é—®é¢˜**: å£°å­è®¡ç®—æŠ¥é”™

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿å®‰è£…å®Œæ•´ä¾èµ–
pip install phonopy spglib h5py pyyaml matplotlib

# æ£€æŸ¥ç‰ˆæœ¬
python -c "import phonopy; print(phonopy.__version__)"
python -c "import spglib; print(spglib.__version__)"
```

### 5.3 æ€§èƒ½é—®é¢˜

**é—®é¢˜**: åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿä¸­ç»“æ„å´©æºƒ

**åŸå› **: EquiformerV2 ä½¿ç”¨éä¿å®ˆåŠ› (ç›´æ¥é¢„æµ‹åŠ›è€Œéä»èƒ½é‡æ¢¯åº¦è®¡ç®—)

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ 1: å‡å°æ—¶é—´æ­¥é•¿
md_result = calc.run_md(
    atoms,
    ensemble="nvt",
    temperature=300,
    timestep=0.5,  # é™ä½åˆ° 0.5 fs (é»˜è®¤ 1.0 fs)
    steps=50000
)

# æ–¹æ¡ˆ 2: ä½¿ç”¨æ›´ä¸¥æ ¼çš„æ¸©åº¦æ§åˆ¶
md_result = calc.run_md(
    atoms,
    ensemble="nvt",
    temperature=300,
    thermostat_time_constant=50,  # å‡å°è€¦åˆå¸¸æ•°
    timestep=0.5
)

# æ–¹æ¡ˆ 3: å…ˆä¼˜åŒ–ç»“æ„
opt_result = calc.optimize(atoms, fmax=0.01)
optimized_atoms = opt_result['atoms']
md_result = calc.run_md(optimized_atoms, ...)
```

#### Q6: åŠ›é¢„æµ‹ä¸å‡†ç¡®

**é—®é¢˜**: åŠ›çš„ MAE è¾ƒé«˜

**åŸå› **: EquiformerV2 çš„éä¿å®ˆåŠ›è®¾è®¡

**è¯´æ˜**:
- EquiformerV2 ç›´æ¥é¢„æµ‹åŠ› (éä¿å®ˆ)ï¼Œè®¡ç®—æ•ˆç‡é«˜ä½†ç‰©ç†ä¸€è‡´æ€§è¾ƒå·®
- å¯¹äºéœ€è¦é«˜ç²¾åº¦ä¿å®ˆåŠ›çš„ä»»åŠ¡ï¼Œæ¨èä½¿ç”¨ MACE æˆ– eSEN

```python
# å¦‚éœ€ä¿å®ˆåŠ›ï¼Œåˆ‡æ¢åˆ°å…¶ä»–æ¨¡å‹
from mace.calculators import mace_mp
calc = mace_mp(model="medium", device="cuda")  # MACE ä½¿ç”¨ä¿å®ˆåŠ›
```

### 5.3 æ€§èƒ½é—®é¢˜

#### Q10: è®¡ç®—é€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. ç¡®ä¿ä½¿ç”¨ GPU
calc = EquiformerV2Inference(device="cuda")

# 2. ä½¿ç”¨å°æ¨¡å‹
calc = EquiformerV2Inference(model_name="EquiformerV2-31M-S2EF")  # è€Œé 153M

# 3. å¢åŠ æ‰¹é‡å¤§å° (é«˜é€šé‡)
results = calc.batch_inference(atoms_list, batch_size=8)

# 4. ä½¿ç”¨æ··åˆç²¾åº¦
calc = EquiformerV2Inference(
    device="cuda",
    precision="float16"
)
```

#### Q11: MD æ¨¡æ‹Ÿä¸ç¨³å®š / èƒ½é‡çˆ†ç‚¸

**é—®é¢˜**: åˆ†å­åŠ¨åŠ›å­¦æ¨¡æ‹Ÿä¸­ç»“æ„å´©æºƒ

**åŸå› **: EquiformerV2 ä½¿ç”¨éä¿å®ˆåŠ› (ç›´æ¥é¢„æµ‹åŠ›è€Œéä»èƒ½é‡æ¢¯åº¦è®¡ç®—)

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ 1: å‡å°æ—¶é—´æ­¥é•¿
md_result = calc.run_md(
    atoms,
    ensemble="nvt",
    temperature=300,
    timestep=0.5,  # é™ä½åˆ° 0.5 fs (é»˜è®¤ 1.0 fs)
    steps=50000
)

# æ–¹æ¡ˆ 2: ä½¿ç”¨æ›´ä¸¥æ ¼çš„æ¸©åº¦æ§åˆ¶
md_result = calc.run_md(
    atoms,
    ensemble="nvt",
    temperature=300,
    thermostat_time_constant=50,  # å‡å°è€¦åˆå¸¸æ•°
    timestep=0.5
)

# æ–¹æ¡ˆ 3: å…ˆä¼˜åŒ–ç»“æ„
opt_result = calc.optimize(atoms, fmax=0.01)
optimized_atoms = opt_result['atoms']
md_result = calc.run_md(optimized_atoms, ...)
```

#### Q12: å¤šè¿›ç¨‹è®¡ç®—é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
```python
# é¿å…åœ¨å¤šè¿›ç¨‹ä¸­å…±äº« CUDA å¼ é‡
from multiprocessing import Pool
from ase.io import read

def worker(structure_file):
    # æ¯ä¸ªè¿›ç¨‹åˆ›å»ºç‹¬ç«‹çš„è®¡ç®—å™¨
    calc = EquiformerV2Inference(
        device="cpu"  # å¤šè¿›ç¨‹å»ºè®®ä½¿ç”¨ CPU
    )
    atoms = read(structure_file)
    return calc.single_point(atoms)

with Pool(processes=4) as pool:
    results = pool.map(worker, structure_files)
```

---

## 6. ä¾èµ–è¯´æ˜

### 6.1 æ ¸å¿ƒä¾èµ–

| åŒ…å | ç‰ˆæœ¬è¦æ±‚ | ç”¨é€” |
|------|---------|------|
| `equiformer-v2` | >= 0.1.0 | EquiformerV2 æ¨¡å‹æ ¸å¿ƒ |
| `e3nn` | >= 0.5.0 | E(3) ç­‰å˜ç¥ç»ç½‘ç»œæ“ä½œ |
| `torch` | >= 2.0.0 | æ·±åº¦å­¦ä¹ æ¡†æ¶ |
| `torch-geometric` | >= 2.3.0 | å›¾ç¥ç»ç½‘ç»œåº“ (GPU ç‰ˆæœ¬) |
| `ase` | >= 3.22.0 | åŸå­æ¨¡æ‹Ÿç¯å¢ƒ |
| `numpy` | >= 1.21.0, < 2.0 | æ•°å€¼è®¡ç®— |
| `scipy` | >= 1.7.0 | ç§‘å­¦è®¡ç®— |

### 6.2 è®¡ç®—ä»»åŠ¡ä¾èµ–

| åŒ…å | ç‰ˆæœ¬è¦æ±‚ | ç”¨é€” |
|------|---------|------|
| `phonopy` | >= 2.20.0 | å£°å­è°±è®¡ç®— |
| `pymatgen` | >= 2023.0.0 | ææ–™ç»“æ„åˆ†æä¸å¤„ç† |
| `spglib` | >= 2.0.0 | ç©ºé—´ç¾¤å¯¹ç§°æ€§åˆ†æ |

### 6.3 å·¥å…·ä¾èµ–

| åŒ…å | ç‰ˆæœ¬è¦æ±‚ | ç”¨é€” |
|------|---------|------|
| `h5py` | latest | HDF5 æ–‡ä»¶è¯»å†™ |
| `matplotlib` | >= 3.5.0 | æ•°æ®å¯è§†åŒ– |
| `pandas` | latest | æ•°æ®åˆ†æä¸å¤„ç† |
| `tqdm` | latest | è¿›åº¦æ¡æ˜¾ç¤º |
| `pyyaml` | latest | YAML é…ç½®æ–‡ä»¶ |
| `prettytable` | latest | è¡¨æ ¼æ ¼å¼è¾“å‡º |

### 6.4 Torch-Geometric æ‰©å±• (GPU ç‰ˆæœ¬)

| åŒ…å | ç‰ˆæœ¬è¦æ±‚ | ç”¨é€” |
|------|---------|------|
| `torch-scatter` | ä¸ PyTorch åŒ¹é… | åˆ†æ•£/èšé›†æ“ä½œ |
| `torch-sparse` | ä¸ PyTorch åŒ¹é… | ç¨€ç–å¼ é‡æ“ä½œ |
| `torch-cluster` | ä¸ PyTorch åŒ¹é… | èšç±»ç®—æ³• |
| `torch-spline-conv` | ä¸ PyTorch åŒ¹é… | æ ·æ¡å·ç§¯ |

### 6.5 å¼€å‘ä¾èµ–

```bash
# æµ‹è¯•å·¥å…·
pip install pytest pytest-cov pytest-xdist

# ä»£ç è´¨é‡
pip install black flake8 mypy isort

# æ–‡æ¡£ç”Ÿæˆ
pip install sphinx sphinx-rtd-theme
```

---

## 7. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 7.1 CPU ä¼˜åŒ–
```bash
# è®¾ç½® OpenMP çº¿ç¨‹æ•° (æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´)
export OMP_NUM_THREADS=16
export MKL_NUM_THREADS=16

# ä½¿ç”¨ Intel MKL (æ›´å¿«çš„çº¿æ€§ä»£æ•°)
conda install mkl mkl-include
```

### 7.2 GPU ä¼˜åŒ–
```python
import torch

# å¯ç”¨ TF32 (Ampere æ¶æ„: A100, RTX 3090)
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

# å¯ç”¨ cuDNN benchmark (è¾“å…¥å¤§å°å›ºå®šæ—¶)
torch.backends.cudnn.benchmark = True

# é¢„åˆ†é… GPU å†…å­˜ (å‡å°‘ç¢ç‰‡åŒ–)
torch.cuda.empty_cache()
```

### 7.3 æ‰¹å¤„ç†ä¼˜åŒ–
```python
# æ ¹æ®ç³»ç»Ÿèµ„æºè°ƒæ•´æ‰¹å¤„ç†å¤§å°
from equiformerv2_inference import EquiformerV2Inference

# å° GPU (8GB)
calc = EquiformerV2Inference(device="cuda", batch_size=8)

# ä¸­ç­‰ GPU (16GB)
calc = EquiformerV2Inference(device="cuda", batch_size=32)

# å¤§ GPU (24GB+)
calc = EquiformerV2Inference(device="cuda", batch_size=64)
```

---

## 8. å¸è½½

```bash
# å¸è½½æ¨ç†åŒ…
pip uninstall equiformerv2-inference

# å¸è½½æ ¸å¿ƒä¾èµ–
pip uninstall equiformer-v2 e3nn torch-geometric

# åˆ é™¤ conda ç¯å¢ƒ
conda deactivate
conda remove -n equiformerv2-gpu --all
# æˆ–
conda remove -n equiformerv2-cpu --all
```

---

## 9. è·å–å¸®åŠ©

- **å¿«é€Ÿå…¥é—¨**: [QUICKSTART.md](equiformerv2-inference/QUICKSTART.md)
- **è¯¦ç»†å®‰è£…**: [INSTALL_GUIDE.md](equiformerv2-inference/INSTALL_GUIDE.md)
- **ç¤ºä¾‹ä»£ç **: [equiformerv2-inference/examples/](equiformerv2-inference/examples/)
- **æµ‹è¯•è„šæœ¬**: [equiformerv2-inference/tests/](equiformerv2-inference/tests/)
- **OCP æ–‡æ¡£**: https://github.com/Open-Catalyst-Project/ocp
- **E3NN æ–‡æ¡£**: https://docs.e3nn.org/

---

## 10. æ¶æ„è¯´æ˜

### EquiformerV2 ç‰¹æ€§
- **ç­‰å˜ Transformer**: åˆ©ç”¨ E(3) ç­‰å˜æ³¨æ„åŠ›æœºåˆ¶
- **åŸå­çº§é¢„æµ‹**: èƒ½é‡ã€åŠ›ã€åº”åŠ›å¼ é‡
- **å¤§è§„æ¨¡é¢„è®­ç»ƒ**: åœ¨ OC20/OC22 æ•°æ®é›†è®­ç»ƒ
- **é«˜æ•ˆæ¨ç†**: æ”¯æŒ batch æ¨ç†å’Œ GPU åŠ é€Ÿ

### E3NN æ ¸å¿ƒæ¦‚å¿µ
- **ä¸å¯çº¦è¡¨ç¤º (Irreps)**: çƒè°å‡½æ•°åŸº
- **å¼ é‡ç§¯**: ç­‰å˜ç‰¹å¾èåˆ
- **æ—‹è½¬ç­‰å˜æ€§**: ä¿æŒç‰©ç†å¯¹ç§°æ€§

---

## 11. æ›´æ–°æ—¥å¿—

### v0.1.0 (2026-01-07)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- æ”¯æŒ EquiformerV2 é¢„è®­ç»ƒæ¨¡å‹
- å®ç°å•ç‚¹èƒ½é‡/åŠ›è®¡ç®—
- æ”¯æŒç»“æ„ä¼˜åŒ– (BFGS, LBFGS)
- æ”¯æŒåˆ†å­åŠ¨åŠ›å­¦ (NVE, NVT, NPT)
- æ”¯æŒå£°å­è°±è®¡ç®—
- æ”¯æŒä½“æ¨¡é‡è®¡ç®—
- CPU/GPU åŒæ¨¡å¼
