# GRACE Inference å®‰è£…æŒ‡å—

> **GRACE**: åŸºäºå›¾æ³¨æ„åŠ›æœºåˆ¶çš„é«˜æ•ˆåŠ›åœºæ¨¡å‹  
> **å¼€å‘å›¢é˜Ÿ**: å›¾æœºå™¨å­¦ä¹ ç ”ç©¶å›¢é˜Ÿ  
> **ç‰¹è‰²**: DGL åŠ é€Ÿã€é«˜æ•ˆå›¾ç¥ç»ç½‘ç»œã€å¤šåœºæ™¯æ¨ç†ä»»åŠ¡

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿè¦æ±‚](#1-ç³»ç»Ÿè¦æ±‚)
2. [å®‰è£…æ–¹æ³•](#2-å®‰è£…æ–¹æ³•)
3. [éªŒè¯å®‰è£…](#3-éªŒè¯å®‰è£…)
4. [GPU é…ç½®](#4-gpu-é…ç½®)
5. [å¸¸è§é—®é¢˜](#5-å¸¸è§é—®é¢˜)
6. [ä¾èµ–è¯´æ˜](#6-ä¾èµ–è¯´æ˜)

---

## 1. ç³»ç»Ÿè¦æ±‚

### æœ€ä½é…ç½®
- **æ“ä½œç³»ç»Ÿ**: Linux, macOS, Windows (WSL2)
- **Python**: 3.9 - 3.11 (æ¨è 3.10)
- **å†…å­˜**: 8GB RAM (æ¨è 16GB+)
- **ç£ç›˜**: 5GB å¯ç”¨ç©ºé—´

### GPU ç‰ˆæœ¬é¢å¤–è¦æ±‚
- **GPU**: NVIDIA GPU (è®¡ç®—èƒ½åŠ› >= 6.0)
- **CUDA**: 11.8 æˆ– 12.1+
- **GPU æ˜¾å­˜**: >= 8GB (æ¨è >= 16GB)
- **é©±åŠ¨**: NVIDIA Driver >= 450.80.02

---

## 2. å®‰è£…æ–¹æ³•

### æ–¹æ³• 1: Pip å®‰è£… (æ¨è)

#### CPU ç‰ˆæœ¬
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n grace-cpu python=3.10
conda activate grace-cpu

# å®‰è£… PyTorch (CPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# å®‰è£… DGL (CPU)
pip install dgl -f https://data.dgl.ai/wheels/repo.html

# å®‰è£… GRACE å’Œä¾èµ–
pip install grace-gnn ase phonopy pymatgen

# å®‰è£…æœ¬æ¨ç†åŒ…
cd GRACE_inference
pip install -r requirements-cpu.txt
```

#### GPU ç‰ˆæœ¬
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n grace-gpu python=3.10
conda activate grace-gpu

# å®‰è£… PyTorch (GPU) - æ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©
# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£… DGL (GPU) - æ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©
# CUDA 11.8
pip install dgl-cu118 -f https://data.dgl.ai/wheels/repo.html

# CUDA 12.1
pip install dgl-cu121 -f https://data.dgl.ai/wheels/repo.html

# å®‰è£… GRACE å’Œä¾èµ–
pip install grace-gnn ase phonopy pymatgen spglib

# å®‰è£…æœ¬æ¨ç†åŒ…
cd GRACE_inference
pip install -r requirements-gpu.txt
```

### æ–¹æ³• 2: Conda å®Œæ•´ç¯å¢ƒ

```bash
# åˆ›å»ºç¯å¢ƒå¹¶å®‰è£…æ‰€æœ‰ä¾èµ–
conda create -n grace python=3.10
conda activate grace

# å®‰è£… PyTorch (GPU)
conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia

# æˆ–å®‰è£… PyTorch (CPU)
conda install pytorch cpuonly -c pytorch

# å®‰è£… DGL (éœ€è¦ä» pip å®‰è£…)
pip install dgl-cu118 -f https://data.dgl.ai/wheels/repo.html  # GPU ç‰ˆæœ¬
# æˆ–
pip install dgl -f https://data.dgl.ai/wheels/repo.html  # CPU ç‰ˆæœ¬

# å®‰è£…å…¶ä»–ä¾èµ–
pip install grace-gnn ase phonopy pymatgen scipy h5py matplotlib pandas tqdm pyyaml prettytable
```

### æ–¹æ³• 3: å¼€å‘è€…å®‰è£… (ä»æºç )

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-org/grace-inference
cd grace-inference/grace-inference

# åˆ›å»ºå¼€å‘ç¯å¢ƒ
conda create -n grace-dev python=3.10
conda activate grace-dev

# å®‰è£… PyTorch å’Œ DGL
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install dgl-cu118 -f https://data.dgl.ai/wheels/repo.html

# ä»¥å¯ç¼–è¾‘æ¨¡å¼å®‰è£…
pip install -e .

# æˆ–ä½¿ç”¨ pip å®‰è£…ä¾èµ–åæœ¬åœ°å®‰è£…
pip install -r requirements-gpu.txt
python setup.py develop
```

---

## 3. éªŒè¯å®‰è£…

### å¿«é€ŸéªŒè¯
```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate grace-gpu  # æˆ– grace-cpu

# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version  # åº”æ˜¾ç¤º 3.10.x

# æ£€æŸ¥æ ¸å¿ƒåŒ…
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "import dgl; print('DGL:', dgl.__version__)"
python -c "import grace_gnn; print('GRACE:', grace_gnn.__version__)"
python -c "import ase; print('ASE:', ase.__version__)"
```

### è¿è¡Œæµ‹è¯•è„šæœ¬
```bash
cd grace-inference

# è¿è¡Œå®‰è£…æµ‹è¯•
python tests/test_install.py

# é¢„æœŸè¾“å‡ºç¤ºä¾‹
# âœ“ Python version: 3.10.11
# âœ“ PyTorch installed: 2.0.1
# âœ“ DGL installed: 1.1.2
# âœ“ GRACE-GNN installed: 0.1.0
# âœ“ ASE installed: 3.22.1
# âœ“ CUDA available: True (GPU version)
# âœ“ DGL CUDA enabled: True
# All tests passed!
```

### è¿è¡Œç¤ºä¾‹è®¡ç®—
```bash
cd examples

# å•ç‚¹èƒ½è®¡ç®—ç¤ºä¾‹
python 01_single_point.py

# é¢„æœŸè¾“å‡º
# Loading GRACE model...
# Computing energy for structure...
# Energy: -156.78 eV
# Forces shape: (24, 3)
# Max force: 0.23 eV/Ã…
```

---

## 4. GPU é…ç½®

### æ£€æŸ¥ GPU å¯ç”¨æ€§

```bash
# æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
python -c "import torch; print('CUDA version:', torch.version.cuda)"
python -c "import torch; print('GPU count:', torch.cuda.device_count())"

# æ£€æŸ¥ DGL GPU æ”¯æŒ
python -c "import dgl; print('DGL CUDA enabled:', dgl.cuda.is_available())"

# æŸ¥çœ‹ GPU ä¿¡æ¯
nvidia-smi
```

### å¤š GPU é…ç½®

```bash
# æŒ‡å®šä½¿ç”¨çš„ GPU (ä½¿ç”¨ GPU 0)
export CUDA_VISIBLE_DEVICES=0

# ä½¿ç”¨å¤šä¸ª GPU (GPU 0 å’Œ 1)
export CUDA_VISIBLE_DEVICES=0,1

# åœ¨ Windows ä¸­
set CUDA_VISIBLE_DEVICES=0
```

### GPU å†…å­˜ä¼˜åŒ–

```python
# åœ¨ Python è„šæœ¬ä¸­
import torch

# å¯ç”¨ cudnn benchmark (åŠ é€Ÿè®¡ç®—)
torch.backends.cudnn.benchmark = True

# è®¾ç½® DGL ä½¿ç”¨çš„ GPU
import dgl
dgl.cuda.set_device(0)  # ä½¿ç”¨ GPU 0

# æ¸…ç©º GPU ç¼“å­˜
torch.cuda.empty_cache()
```

### æ€§èƒ½å»ºè®®

| ç¡¬ä»¶é…ç½® | æ¨èç”¨é€” | æ‰¹é‡å¤§å° |
|---------|---------|---------|
| CPU only | å°åˆ†å­æµ‹è¯•ã€å¼€å‘è°ƒè¯• | 1-4 |
| GPU 8GB | ä¸­ç­‰ MOF ç»“æ„ | 4-8 |
| GPU 16GB | å¤§å‹ MOFã€é•¿æ—¶ MD | 8-16 |
| GPU 24GB+ | é«˜é€šé‡è®¡ç®—ã€è¶…å¤§ç»“æ„ | 16-32 |

---

## 5. å¸¸è§é—®é¢˜

### Q1: DGL å®‰è£…å¤±è´¥
**é—®é¢˜**: `ERROR: Could not find a version that satisfies the requirement dgl`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ³• 1: ä»å®˜æ–¹æºå®‰è£…
pip install dgl -f https://data.dgl.ai/wheels/repo.html

# æ–¹æ³• 2: æŒ‡å®š CUDA ç‰ˆæœ¬
pip install dgl-cu118 -f https://data.dgl.ai/wheels/repo.html  # CUDA 11.8
pip install dgl-cu121 -f https://data.dgl.ai/wheels/repo.html  # CUDA 12.1

# æ–¹æ³• 3: CPU ç‰ˆæœ¬
pip install dgl -f https://data.dgl.ai/wheels/repo.html
```

### Q2: CUDA ç‰ˆæœ¬ä¸åŒ¹é…
**é—®é¢˜**: `RuntimeError: CUDA error: no kernel image is available for execution`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ç³»ç»Ÿ CUDA ç‰ˆæœ¬
nvcc --version
nvidia-smi  # æŸ¥çœ‹é©±åŠ¨æ”¯æŒçš„æœ€é«˜ CUDA ç‰ˆæœ¬

# é‡æ–°å®‰è£…åŒ¹é…çš„ PyTorch å’Œ DGL
# ä¾‹å¦‚ CUDA 11.8
pip uninstall torch dgl
pip install torch --index-url https://download.pytorch.org/whl/cu118
pip install dgl-cu118 -f https://data.dgl.ai/wheels/repo.html
```

### Q3: å¯¼å…¥ GRACE å¤±è´¥
**é—®é¢˜**: `ModuleNotFoundError: No module named 'grace_gnn'`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ˜¯å¦æ­£ç¡®æ¿€æ´»ç¯å¢ƒ
conda activate grace-gpu

# é‡æ–°å®‰è£… grace-gnn
pip install --upgrade grace-gnn

# å¦‚æœä»æºç å®‰è£…
cd grace-inference
pip install -e .
```

### Q4: DGL å›¾æ„å»ºé”™è¯¯
**é—®é¢˜**: `DGLError: Expect number of features to match number of nodes`

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¡®ä¿èŠ‚ç‚¹ç‰¹å¾å’ŒèŠ‚ç‚¹æ•°åŒ¹é…
import dgl
import torch

# æ­£ç¡®æ„å»ºå›¾
g = dgl.graph((src, dst))
g.ndata['feat'] = node_features  # ç¡®ä¿ shape = (num_nodes, feat_dim)

# æ£€æŸ¥ç»´åº¦
print(f"Nodes: {g.num_nodes()}, Features: {g.ndata['feat'].shape}")
```

### Q5: å†…å­˜ä¸è¶³é”™è¯¯
**é—®é¢˜**: `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```python
# 1. å‡å°‘æ‰¹é‡å¤§å°
batch_size = 4  # æ”¹ä¸ºæ›´å°çš„å€¼

# 2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
torch.cuda.empty_cache()

# 3. é™ä½æ¨¡å‹ç²¾åº¦ (å¦‚æœæ”¯æŒ)
model.half()  # ä½¿ç”¨ FP16

# 4. ä½¿ç”¨ CPU è¿è¡Œ
device = 'cpu'
```

### Q6: Windows è·¯å¾„é—®é¢˜
**é—®é¢˜**: è·¯å¾„åˆ†éš”ç¬¦é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```python
import os
from pathlib import Path

# ä½¿ç”¨ Path å¤„ç†è·¯å¾„
model_path = Path("models/grace_model.pt")
structure_path = Path("structures/MOF.cif")

# æˆ–ä½¿ç”¨ os.path.join
model_path = os.path.join("models", "grace_model.pt")
```

### Q7: DGL ç‰ˆæœ¬å…¼å®¹æ€§
**é—®é¢˜**: `ImportError: DGL requires torch >= 1.12.0`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿ PyTorch ç‰ˆæœ¬æ»¡è¶³è¦æ±‚
pip install torch>=2.0.0

# æˆ–é™çº§ DGL
pip install dgl==1.0.0  # æ ¹æ® PyTorch ç‰ˆæœ¬é€‰æ‹©å…¼å®¹çš„ DGL
```

---

## 6. ä¾èµ–è¯´æ˜

### æ ¸å¿ƒä¾èµ–

| åŒ…å | ç‰ˆæœ¬è¦æ±‚ | ç”¨é€” | é‡è¦æ€§ |
|------|---------|------|--------|
| `python` | 3.9-3.11 | è¿è¡Œç¯å¢ƒ | å¿…éœ€ |
| `torch` | >=1.12.0 | æ·±åº¦å­¦ä¹ æ¡†æ¶ | å¿…éœ€ |
| `dgl` | >=1.0.0 | å›¾ç¥ç»ç½‘ç»œåº“ | å¿…éœ€ |
| `grace-gnn` | >=0.1.0 | GRACE æ¨¡å‹ | å¿…éœ€ |
| `ase` | >=3.22.0 | åŸå­æ¨¡æ‹Ÿç¯å¢ƒ | å¿…éœ€ |

### è®¡ç®—ä¾èµ–

| åŒ…å | ç‰ˆæœ¬è¦æ±‚ | ç”¨é€” |
|------|---------|------|
| `numpy` | >=1.21.0,<2.0.0 | æ•°å€¼è®¡ç®— |
| `scipy` | >=1.7.0 | ç§‘å­¦è®¡ç®— |
| `phonopy` | >=2.20.0 | å£°å­è®¡ç®— |
| `pymatgen` | >=2023.0.0 | ææ–™åˆ†æ |

### å·¥å…·ä¾èµ–

| åŒ…å | ç”¨é€” |
|------|------|
| `h5py` | HDF5 æ–‡ä»¶æ”¯æŒ |
| `matplotlib` | ç»˜å›¾å¯è§†åŒ– |
| `pandas` | æ•°æ®åˆ†æ |
| `tqdm` | è¿›åº¦æ¡æ˜¾ç¤º |
| `pyyaml` | YAML é…ç½® |
| `prettytable` | è¡¨æ ¼æ ¼å¼åŒ– |

### DGL è¯¦ç»†è¯´æ˜

**DGL (Deep Graph Library)** æ˜¯ GRACE çš„æ ¸å¿ƒä¾èµ–ï¼Œæä¾›é«˜æ•ˆçš„å›¾ç¥ç»ç½‘ç»œè®¡ç®—ï¼š

- **åŠŸèƒ½**: å›¾æ„å»ºã€æ¶ˆæ¯ä¼ é€’ã€å¼‚æ„å›¾æ”¯æŒ
- **ä¼˜åŠ¿**: GPU åŠ é€Ÿã€å†…å­˜ä¼˜åŒ–ã€æ‰¹å¤„ç†æ”¯æŒ
- **ç‰ˆæœ¬é€‰æ‹©**:
  - CPU: `dgl` (é€šç”¨ç‰ˆæœ¬)
  - CUDA 11.8: `dgl-cu118`
  - CUDA 12.1: `dgl-cu121`

**å®‰è£…æŒ‡å—**:
```bash
# CPU ç‰ˆæœ¬
pip install dgl -f https://data.dgl.ai/wheels/repo.html

# GPU ç‰ˆæœ¬ (CUDA 11.8)
pip install dgl-cu118 -f https://data.dgl.ai/wheels/repo.html

# GPU ç‰ˆæœ¬ (CUDA 12.1)
pip install dgl-cu121 -f https://data.dgl.ai/wheels/repo.html
```

**DGL vs PyTorch Geometric**:
- DGL æä¾›æ›´çµæ´»çš„æ¶ˆæ¯ä¼ é€’æœºåˆ¶
- æ›´å¥½çš„å¼‚æ„å›¾æ”¯æŒ
- ä¸ PyTorch æ·±åº¦é›†æˆ
- GRACE ä¸“é—¨é’ˆå¯¹ DGL ä¼˜åŒ–

### å¯é€‰ä¾èµ–

```bash
# è¿›é˜¶åˆ†æå·¥å…·
pip install spglib           # ç©ºé—´ç¾¤åˆ†æ
pip install networkx         # å›¾åˆ†æ
pip install plotly           # äº¤äº’å¼å¯è§†åŒ–

# æ€§èƒ½åˆ†æ
pip install memory_profiler  # å†…å­˜åˆ†æ
pip install line_profiler    # ä»£ç æ€§èƒ½åˆ†æ
```

### ä¾èµ–ç‰ˆæœ¬ç»„åˆæ¨è

#### ç¨³å®šç»„åˆ (æ¨è)
```txt
python==3.10.11
torch==2.0.1
dgl-cu118==1.1.2
grace-gnn==0.1.0
ase==3.22.1
phonopy==2.20.0
```

#### æœ€æ–°ç»„åˆ (å‰æ²¿)
```txt
python==3.11.5
torch==2.1.0
dgl-cu121==1.1.3
grace-gnn==0.2.0
ase==3.23.0
phonopy==2.21.0
```

### ä¾èµ–å†²çªè§£å†³

```bash
# å¦‚æœé‡åˆ°ä¾èµ–å†²çª
pip install --upgrade pip setuptools wheel

# ä½¿ç”¨ conda è§£å†³å¤æ‚ä¾èµ–
conda install -c conda-forge numpy scipy

# åˆ›å»ºå¹²å‡€ç¯å¢ƒ
conda create -n grace-clean python=3.10
conda activate grace-clean
pip install -r requirements-gpu.txt
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå…¥é—¨æŒ‡å—](grace-inference/QUICKSTART.md)
- [API å‚è€ƒæ‰‹å†Œ](GRACE_inference_API_reference.md)
- [æ¨ç†ä»»åŠ¡è¯´æ˜](GRACE_inference_tasks.md)
- [DGL å®˜æ–¹æ–‡æ¡£](https://docs.dgl.ai/)
- [PyTorch æ–‡æ¡£](https://pytorch.org/docs/)

---

## ğŸ†˜ è·å–å¸®åŠ©

- **GitHub Issues**: æäº¤ bug æŠ¥å‘Šæˆ–åŠŸèƒ½è¯·æ±‚
- **è®¨è®ºåŒº**: æŠ€æœ¯äº¤æµå’Œé—®é¢˜è§£ç­”
- **æ–‡æ¡£**: æŸ¥çœ‹å®Œæ•´ä½¿ç”¨æŒ‡å—
- **ç¤ºä¾‹**: å‚è€ƒ `examples/` ç›®å½•ä¸­çš„ä»£ç 

---

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](grace-inference/LICENSE) æ–‡ä»¶

---

**æœ€åæ›´æ–°**: 2026å¹´1æœˆ  
**ç»´æŠ¤å›¢é˜Ÿ**: GRACE Inference å¼€å‘ç»„
